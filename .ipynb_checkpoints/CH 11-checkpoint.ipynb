{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39235b3-71fb-49a3-9ba2-d6ddf5732dce",
   "metadata": {},
   "source": [
    "# Chapter 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3d184b-bed5-4b46-90ff-1f9788853b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanishing or Exploding gradients\n",
    "#might not have training data for such a large network\n",
    "#Training may be very slow\n",
    "#overfitting\n",
    "#recurrent gradient problem surfaces in RNN\n",
    "#differnt layers may learn at widely different speeds\n",
    "#problem with sigmoid function gradient near saturation almost vanished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0c1bcb-ca09-45e0-ab37-a20b78d3cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glorot initialization mean=0, var^2 = 1/fan_avg\n",
    "#or uniform distribution b/w -r & +r with r=(3/fan_avg)^(1/2) = (3*var^2)^(1/2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0b91a8-74e3-4b28-90f7-beef3a0d897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#he_avg_int=keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "#keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365746c3-9c40-4ccf-85b7-76240cd9fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametric leaky relu >> relu on large image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4fa96a-0fae-4d7b-a906-4f35c1c4135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elu outperformed all versions of relu\n",
    "#scaled elu (SELU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69b020a-d829-42cc-bb1f-8834bbbd29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to apply leakyRelu write keras.layers.leakyReLU(alpha=0.2) after the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed80eee-519c-4d31-abd8-02a5a2473321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442b9e45-616e-4fad-b771-13d286a2b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c052b1f-cb1d-448c-8bef-c30fd16e1f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 784)               3136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271346 (1.04 MB)\n",
      "Trainable params: 268978 (1.03 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2002e4c8-cc4b-4dfa-929c-773c0ab4b424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93ea4b36-d681-4fc7-b55f-0ff52dac0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add BN before activation just add activation separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "389ff7bb-71da-4466-80aa-a833aea9254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning\n",
    "model_A= keras.models.load_model(\"xyz.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d0078a-49f1-4d5a-8020-34ffb2cb9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10d6cd74-dfa5-411c-b739-f834a8be5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d60111-4762-4e34-ac70-e5a1e415e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d6d2f4d-f8be-4ef7-a681-8d17a5d405db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"bindary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d30fa274-dfd7-4c26-b555-bed14c595ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ac247bd-508e-4617-a204-d637eb3e78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f63c94-f160-42c9-bf38-4c84e9343b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "405ab48d-0fcb-4678-ab80-c2a9c5a0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9eaa0-3bb3-47af-b2f9-3d15d79be110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable=True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-4) #default=1e-2\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916e986-5e98-4daf-8e51-c367e3cd3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa3588e-1a2a-4427-ba16-7802b2c88189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsupervised learning with restricted boltzmann machines (RBMs)\n",
    "#RBM\n",
    "#autoencoders or GANs instead of RBMs\n",
    "#Pretraining on an Auxilary Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c193e-147d-49ce-b19e-8ec85624fee0",
   "metadata": {},
   "source": [
    "Fast Optimizers\n",
    "Until now we have done\n",
    "-Initialization\n",
    "-Using a good activation function\n",
    "-Batch Normalization\n",
    "-Reusing parts of pretrained networks\n",
    "\n",
    "We need faster optimizer than gradient descent.\n",
    "\n",
    "Popular ones: momentum, Nesterov Accelerated Gradient, AdaGrad, RMSProp, Adam and Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77fa2ea-58b8-454f-8c5f-c3c22d8c377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Momentum (Cares about prev gradients (rolling ball down a slope))\n",
    "#beta=momentum (0-1), typically 0.9\n",
    "#m=beta*m-eta*del_theta*J_theta\n",
    "#theta=theta+m\n",
    "#optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690c6ec7-900a-4456-b141-e34a8ef01f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nesterov Accelerated Gradient\n",
    "#doesnt measure gradient at theta but slightly ahead at (theta+beta*m)\n",
    "# i.e., J(theta+beta*m)\n",
    "#simply set nesterov=True while creating SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b6eb06-87a3-43ae-9782-ce33eb74dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaGrad\n",
    "#scaling down the gradient vector along the steepest dimensions\n",
    "#to correct its direction\n",
    "#requires much less tuning of lear_rate\n",
    "#frequently performs well for quadratic problems\n",
    "#often stops too early when training nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "331641c0-f20c-41ac-9e96-6e34246f2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp\n",
    "#fixes adagrad by accumulating gradients from most recent iterations\n",
    "#does this by using exp decay in first step\n",
    "#optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb23ac6-49e9-430b-9845-323def667f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam and Nadam Optimization\n",
    "#adaptive movement estimation combines momentum and RMSProp\n",
    "#keeps track of both, exponentially deacaying past gradient and past squared gradients\n",
    "#keras.backend.set_epsilon()\n",
    "#optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5752baac-7cdc-4112-b626-aae1033d8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two variants of Adam\n",
    "#AdaMax - replaces norm by max(B_2*s, del_theta*J)\n",
    "#Nadam - Adam + Nesterov\n",
    "#adaptive optimization may lead to solutions that generalize poorly\n",
    "#when disappointed with mode try using simple Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32cdb9d1-be6b-4015-a9fb-5c1a35fbfb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkout tensorflow model opt toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779d31b-4ee8-4e96-aae9-ed58b474c80b",
   "metadata": {},
   "source": [
    "Learn rate Scheduling\n",
    "-Power scheduling\n",
    "    eta = eta_0/(1+t/s)^c\n",
    "-Exponential scheduling\n",
    "    eta = eta_0 0.1^(t/s)\n",
    "-Piecewise Constant Scheduling\n",
    "-Perfomance scheduling\n",
    "    measure validation error every N steps reduce lr by lambda when error stops dropping\n",
    "-1cycle scheduling\n",
    "    first increasing then decreasing lower one is roughly 1/10th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b582c18e-4ea2-47cc-a579-b38d54739f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#power scheduling\n",
    "#optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-4)\n",
    "#exp and piecewise\n",
    "def exp_decay(lr0, s):\n",
    "    def exp_decay_fn(epoch):\n",
    "        return lr0*0.1**(epoch/s)\n",
    "    return exp_decay_fn\n",
    "exp_decay_fn = exp_decay(lr0=0.01, s=20)\n",
    "\n",
    "#next create a learning rate scheduler callback\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exp_decay_fn)\n",
    "#history= model.fit(X_train_scheduled, y_train,[...], callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8740825-d14e-4f60-97c2-0d8d3fdaf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#piecewise\n",
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch<5:\n",
    "        return 0.01\n",
    "    elif epoch<15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f00c682-e17d-4fe0-bdb4-a63223458c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance scheduling\n",
    "lr_scheduler_perform = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4411bf62-8e62-4fe1-9612-b568826b3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.optimizers.schedules\n",
    "\n",
    "#s=20*len(X_train)//32 #number of steps in 20 epochs (batch size = 32)\n",
    "#learning_rate=keras.optimizers.schedules.ExponentialDecay(0.01,s,0.1)\n",
    "#optimizer = keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "#this is specific to tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc91a854-7140-4d29-86ef-e484724b2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([keras.layers.Flatten(input_shape=[28,28]),\n",
    "                               RegularizedDense(300),\n",
    "                               RegularizedDense(100),\n",
    "                               RegularizedDense(10,\n",
    "                               activation=\"softmax\",\n",
    "                               kernel_initializer=\"glorot_uniform\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a7b9b6-27a3-4eed-948e-77b51bf01e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1cycle scheduling\n",
    "#create a custom callback that modifies lr at each itr\n",
    "# by changing self.model.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4638d189-ec46-41b4-97fb-c305775f213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 and l2 regularization\n",
    "#l2 constraints connection weights, l1 to have a sparse model\n",
    "#layer = keras.layers.Dense(100,activation=\"elu\",\n",
    "#kernel_initializer = \"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c26f393b-2274-4a10-aef8-76f0749ecab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                    activation=(\"elu\"),\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    kernel_regularizer=keras.regularizers.l2(0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51d517a1-6f7b-4c34-b2a0-97a77ec0b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout\n",
    "#WOW\n",
    "#keras.layers.Dropout (dropout before every dense layer)\n",
    "#if model overfits, u can increase the dropout rate\n",
    "#alpha dropout with selu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca33a981-d85e-462c-8d62-679223c3c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monte-Carlo Dropout\n",
    "#y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "#                     for sample in range(100)])\n",
    "# y_proba = y_probas.mean(axis=0)\n",
    "# np.round(model.predict(X_test_scaled[:1]), 2)\n",
    "# np.round(y_probas[:,:1], 2)\n",
    "# np.round(y_proba[:1],2)\n",
    "# y_std = y_probas.std(axis=0)\n",
    "# np.round(y_std[:1], 2)\n",
    "\n",
    "#accuracy = np.sum(y_pred == y_test)/len(y_test)\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bfead15-aa1c-42b2-8f6d-40742fe061e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with other layers like BatchNorm, we shouldnt use above method\n",
    "# just use the following instead of dropout layers\n",
    "\n",
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3904ff3-b43c-4f57-945a-66113cda5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max-Norm Regularization\n",
    "#kernel_constraint=keras.constraints.max_norm(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
